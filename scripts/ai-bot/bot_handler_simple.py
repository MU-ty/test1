#!/usr/bin/env python3
"""
AI Bot Handler - Simplified Version
ËæìÂá∫Ê†ºÂºè‰ºòÂåñ‰ª•ÈÄÇÈÖç GitHub Issue ËØÑËÆ∫
"""

import os
import sys
import json

# Á°Æ‰øùËæìÂá∫ÂÆûÊó∂Âà∑Êñ∞
sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1, encoding='utf-8')
sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1, encoding='utf-8')

# Á¶ÅÁî®Êó•Âøó‰ª•‰øùÊåÅËæìÂá∫Ê∏ÖÊ¥Å
import logging
logging.disable(logging.CRITICAL)

def main():
    # Ëé∑ÂèñÁéØÂ¢ÉÂèòÈáè
    url = os.getenv('BOT_URL')
    category = os.getenv('BOT_CATEGORY', 'activity')
    models_token = os.getenv('GH_MODELS_TOKEN')
    
    if not url:
        print("‚ùå No URL provided")
        return False
    
    if not models_token:
        print("‚ùå GH_MODELS_TOKEN not configured")
        return False
    
    # Ê≠•È™§1ÔºöÁà¨ÂèñÁΩëÈ°µ
    try:
        from web_scraper import WebScraper
        scraper = WebScraper()
        result = scraper.scrape(url)
        
        if not result['success']:
            print(f"‚ùå Failed to scrape: {result['error']}")
            return False
        
        scraped_text = result['text']
        metadata = result['metadata']
    
    except Exception as e:
        print(f"‚ùå Scraping error: {str(e)}")
        return False
    
    # Ê≠•È™§2ÔºöAIÂàÜÊûê
    try:
        from ai_analyzer import ActivityAnalyzer
        analyzer = ActivityAnalyzer(models_token)
        analysis = analyzer.analyze(
            text=scraped_text,
            category=category,
            url=url
        )
        
        if not analysis['success']:
            print(f"‚ùå AI analysis failed: {analysis['error']}")
            return False
        
        data = analysis['data']
    
    except Exception as e:
        print(f"‚ùå AI error: {str(e)}")
        return False
    
    # Ê≠•È™§3ÔºöÊ†ºÂºèÂåñËæìÂá∫Ôºà‰æõ Issue ËØÑËÆ∫ÊòæÁ§∫Ôºâ
    print("‚úÖ **Activity Extracted Successfully!**")
    print("")
    print("üìå **Title**")
    print(f"> {data.get('title', 'N/A')}")
    print("")
    print("üìù **Description**")
    desc = data.get('description', 'N/A')
    if desc and desc != 'N/A':
        print(f"> {desc[:200]}")
    else:
        print("> No description available")
    print("")
    print("üóìÔ∏è **Date**")
    start = data.get('start_date', 'N/A')
    end = data.get('end_date', 'N/A')
    print(f"> {start} to {end}")
    print("")
    print("üìç **Location**")
    loc = data.get('location', 'N/A')
    if loc and loc not in ['N/A', 'null']:
        print(f"> {loc}")
    else:
        print("> Online")
    print("")
    print("üè∑Ô∏è **Tags**")
    tags = data.get('tags', [])
    if tags:
        tags_str = ", ".join(tags)
        print(f"> {tags_str}")
    else:
        print("> No tags")
    print("")
    print("üîó **Source**")
    print(f"> {url}")
    print("")
    print("---")
    print("")
    print("‚ú® **Next Steps:**")
    print("- Review the extracted information above")
    print("- Reply with feedback if any corrections are needed")
    
    return True

if __name__ == '__main__':
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"‚ùå Fatal error: {str(e)}")
        sys.exit(1)
